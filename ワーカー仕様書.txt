インポート後などに頻回して行うバッチ処理
worker_jobsのpriority(昇順) > created_at(昇順)の順番で、job_typeによって異なる種類の処理を行っていく。
別プロジェクトでOllamaを用いて処理を行うコードがあるので、参考に記載します。

OLLAMA_URL = "http://localhost:11434/api/generate"

def call_ollama(prompt: str) -> dict[str, Any]:
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0,
            "top_p": 0.8,
            "repeat_penalty": 1.1,
        },
    }
    req = urllib.request.Request(
        OLLAMA_URL,
        data=json.dumps(payload).encode("utf-8"),
        headers={"Content-Type": "application/json"},
        method="POST",
    )
    logger.info("Ollama request prompt: %s", prompt)
    with urllib.request.urlopen(req, timeout=300000) as resp:
        body = resp.read().decode("utf-8")
        logger.info("Ollama response status=%s body=%s", resp.status, body)
        return json.loads(body)


【utterance_role】
・utterance_roles一覧を取得し、uttelance_role_nameを「/」区切りで連結する = allowed_terms
・MODEL_NAME = "gpt-oss:20b"
・prompt ="あなたは分類器です。出力は2行のみ。\n"
"1行目：許可単語一覧から1つを完全一致で出力。\n"
"2行目：自信度を0.00〜1.00で出力。\n"
"他の文章は禁止。\n\n"
"許可単語一覧：\n"
f"{allowed_terms}\n\n"
"contents：\n"
f"{utterance['contents']}"
・response受け取り後
　　・response内で一番最初に出てきたutterance_role_nameに完全一致するutterance_role_idを、utterance.utterance_role_idに格納
　　・response内の数値のうち、最小値をutterance.utterance_role_confidenceに格納。

【did_asked_model】
・MODEL_NAME = "gpt-oss:20b"
・prompt ="以下のテキストから事象・概念に対して定義している箇所を、区切り線「---」を設けて列挙してください。\n"
"他の文章は禁止。\n\n"
"contents：\n"
f"{utterance['contents']}"
・response受け取り後
　　・response内を「---」で区切り、それらをseedsにINSERTする
　　　　・seed_id = 生成UUID
　　　　・seed_type = seed
　　　　・body = 区切ったテキスト
　　　　・created_from = utterance
　　　　・review_status = auto
　　　　・created_at = 現在時刻
　　　　・updated_at = 現在時刻
　　・utterance_seedsにINSERTする
　　　　・utterance_id = 読み込ませたutteranceのutterance_id
　　　　・seed_id = 生成したseed_id
　　　　・relation_type = derived_from
　　　　・created_at = 現在時刻
　　・worker_jobsにINSERTする
　　　　・job_id = 生成UUID
　　　　・job_type = embedding
　　　　・target_table = utterance
　　　　・target_id = 該当utterance_id
　　　　・status = queued
　　　　・priority = 10
　　　　・created_at = 現在日時
　　　　・updated_at = 現在日時
　　・utterancesをUPDATEする
　　　　・did_asked_model = 1
　　　　・updated_at = 現在日時

【did_asked_knowledge】
・MODEL_NAME = "gpt-oss:20b"
・prompt ="以下のテキストから知識と呼べる箇所を、区切り線「---」を設けて列挙してください。\n"
"他の文章は禁止。\n\n"
"contents：\n"
f"{utterance['contents']}"
・response受け取り後
　　・response内を「---」で区切り、それらをseedsにINSERTする
　　　　・seed_id = 生成UUID
　　　　・seed_type = seed
　　　　・body = 区切ったテキスト
　　　　・created_from = utterance
　　　　・review_status = auto
　　　　・created_at = 現在時刻
　　　　・updated_at = 現在時刻
　　・utterance_seedsにINSERTする
　　　　・utterance_id = 読み込ませたutteranceのutterance_id
　　　　・seed_id = 生成したseed_id
　　　　・relation_type = derived_from
　　　　・created_at = 現在時刻
　　・worker_jobsにINSERTする
　　　　・job_id = 生成UUID
　　　　・job_type = embedding
　　　　・target_table = utterance
　　　　・target_id = 該当utterance_id
　　　　・status = queued
　　　　・priority = 10
　　　　・created_at = 現在日時
　　　　・updated_at = 現在日時
　　・utterancesをUPDATEする
　　　　・did_asked_knowledge = 1
　　　　・updated_at = 現在日時

【embedding】
・MODEL_NAME = "paraphrase-multilingual:latest"
・prompt = f"{worker_jobs.target_table['contents']}"
・response受け取り後
　　・responseの内容をL2正規化する
　　・embeddingsにINSERTする
　　　　・embedding_id = 生成UUID
　　　　・target_type = worker_jobs.target_table
　　　　・target_id = worker_jobs.target_id
　　　　・model_name = paraphrase-multilingual
　　　　・dims = ベクトルの次元数（要素数）
　　　　・vector = L2正規化したresponse(正規化に失敗した場合はresponseの内容)
　　　　・is_l2_normalized = 1(正規化に失敗した場合は0)
　　　　・created_at = 現在時刻
　　（以降はseed・clusterのみ実行）
　　・embeddings内でvectorを用いて近傍を検索し、上位20個のseed・clusterのうち、clusterが存在した場合には上位2個に対してedgesをINSERTする。
　　　　・edge_id = 生成UUID
　　　　・src_type = worker_jobs.target_table
　　　　・src_id = worker_jobs.target_id
　　　　・dst_type = cluster
　　　　・dst_id = 該当cluster_id
　　　　・edge_type = part_of
　　　　・weight = 該当clusterとworker_jobsで指定した要素の類似度
　　　　・is_active = 1
　　　　・created_at = 現在時刻
　　　　・updated_at = 現在時刻
　　・clusterにedgesを追加した場合、layout_pointsをINSERTする。
　　　　・layout_id = layout_ruins.scope_cluster_id = 該当cluster_idに紐づいているlayout_id
　　　　・target_type = worker_jobs.target_table
　　　　・target_id = worker_jobs.target_id
　　　　・x = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のxの平均値
　　　　・y = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のyの平均値
　　　　・is_active = 1
　　　　・created_at = 現在時刻
　　・clusterにedgesを追加したtarget_typeがseedの場合、utterance_seedで紐づいているutteranceすべてに対して、layout_pointsをINSERTする。
　　　　・layout_id = layout_ruins.scope_cluster_id = 該当cluster_idに紐づいているlayout_id
　　　　・target_type = utterance
　　　　・target_id = 該当のutterance_id
　　　　・x = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のxの平均値
　　　　・y = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のyの平均値
　　　　・is_active = 1
　　　　・created_at = 現在時刻
　　・clusterにedgesを追加したtarget_typeがseedの場合、utterance_seedで紐づいているutteranceすべてに対して、layout_runs.scope_type = globalに紐づいているlayout_printsが存在したら、layout_points.is_active = 0にUPDATEする。
　　・clusterにedgesを追加しなかった場合、layout_runs.scope_type = globalのlayout_runsに紐づくlayout_pointsをINSERTする。
　　　　・layout_runs.scope_type = globalのレコードがない場合、以下をINSERTする
　　　　　　・layout_id = 生成UUID
　　　　　　・algorithm = umap
　　　　　　・dims = 2
　　　　　　・scope_type = global
　　　　　　・params_json = {"n_components":2, "n_neighbors":15, "min_dist":0.1, "random_state":42}
　　　　　　・is_active = 1
　　　　　　・created_at = 現在時刻
　　　　・layout_pointsをINSERTする
　　　　　　・layout_id = layout_runs.scope_type = globalのlayout_runsのlayout_id
　　　　　　・target_type = worker_jobs.target_table
　　　　　　・target_id = worker_jobs.target_id
　　　　　　・x = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のxの平均値
　　　　　　・y = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のyの平均値
　　　　　　・is_active = 1
　　　　　　・created_at = 現在時刻
　　・clusterにedgesを追加せずtarget_typeがseedの場合、utterance_seedで紐づいているutteranceすべてに対して、layout_pointsをINSERTする。
　　　　・layout_id = layout_runs.scope_type = globalのlayout_runsのlayout_id
　　　　・target_type = utterance
　　　　・target_id = 該当のutterance_id
　　　　・x = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のxの平均値
　　　　・y = layout_runsに紐づいているlayout_pointsのうち、近傍検索で上位10件のyの平均値
　　　　・is_active = 1
　　　　・created_at = 現在時刻
　　・embeddings内でvectorを用いて近傍を検索し、上位10個のseed・clusterに対してedgesをINSERTする。
　　　　・edge_id = 生成UUID
　　　　・src_type = worker_jobs.target_table
　　　　・src_id = worker_jobs.target_id
　　　　・dst_type = 該当要素名(utterance / seed / cluster)
　　　　・dst_id = 該当要素id(utterance_id / seed_id / cluster_id)
　　　　・edge_type = near
　　　　・weight = 該当clusterとworker_jobsで指定した要素の類似度
　　　　・is_active = 1
　　　　・created_at = 現在時刻
　　　　・updated_at = 現在時刻

【embedding_utterance】
・utterance_idに紐づいているutterance_splitsを列挙する
・各utterance_splitsに紐づいているembeddingsを列挙する
・全てのutterance_splitsにembeddingsが紐づいている、かつ全てのembeddingsがis_l2_normalized = 1の場合、該当するすべてのvectorの平均を取り、L2正規化を行う。
・embeddingsにINSERTする
　　・embedding_id = 生成UUID
　　・target_type = utterance
　　・target_id = work_jobs.target_id
　　・model_name = 任意のutterance_splitsに紐づいているembeddings.model_name
　　・dims = 任意のutterance_splitsに紐づいているembeddings.model_name
　　・vector = 平均化＆L2正規化した値
　　・is_l2_normalized = 1
　　・created_at = 現在時刻

【cluster_body】
・edgesのうち、dst_type = cluster、dst_id = worker_jobs.target_id、edge_type = part_ofに該当するseedのcontensを改行区切りで連結する。
・MODEL_NAME = "gpt-oss:20b"
・prompt ="以下のテキストから概要・まとめを出力してください。\n"
"他の文章は禁止。\n\n"
"contents：\n"
f"{連結したテキスト}"
・response受け取り後
　　・clusters.cluster_id = worker_jobs.target_idにUPDATEする
　　　　・cluster_overview = 受け取ったresponse
　　　　・updated_at = 現在時刻

---

夜間などに行う重たいバッチ処理
・全seedの近傍距離の平均をall_seed_info.avg_seed_distanceとして、近傍距離の中央値をall_seed_info.median_seed_distanceとしてINSERTorUPDATEする。

・clusterの分割
　　・edges.dst_type = cluster、edges.edge_type = part_ofで検索したとき100件以上存在するedges.dst_idを探す。
　　　　・存在しない場合：スキップ
　　　　・存在する場合：全てのseedに紐づいているembeddings.is_l2_normalized = 1ならば、以下の処理を行う。それ以外の場合はスキップ。
　　　　　　・該当するseedに対して、密度関数(FAISSでkNNをとり(k=30)、その中央値を見る)を調整し2つ以上にグループを分裂させる（分裂後は1グループあたり20seed以上）
　　　　　　・対象のclusterはclusters.is_archived = 1、updated_at = 現在時刻にUPDATEする。
　　　　　　・対象のclusterに紐づくedgesについて(srcとdstのどちらも確認)、is_active = 0、updated_at = 現在時刻にUPDATEする。
　　　　　　・対象のclusterに紐づくlayout_runsについて、is_active = 0にUPDATEする。
　　　　　　・対象のclusterに紐づくlayout_ruinsに属していたすべてのlayout_pointsについて、is_active = 0にUPDATEする。
　　　　　　・対象のclusterが紐づいていたlayout_pointsについて、is_active = 0にUPDATEする。
　　　　　　・各グループに対して以下の処理を行う。
　　　　　　　　・clustersをINSERTする
　　　　　　　　　　・cluster_id = 生成UUID
　　　　　　　　　　・cluster_level = cluster
　　　　　　　　　　・is_archived = 0
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　　　・updated_at = 現在時刻
　　　　　　　　・所属するseedのembeddings.vectorの平均を取得し、embeddingsにINSERTする
　　　　　　　　　　・embedding_id = 生成UUID
　　　　　　　　　　・target_type = cluster
　　　　　　　　　　・target_id = 生成したcluster_id
　　　　　　　　　　・model_name = 大元のclusterに紐づいていたembeddings.model_name
　　　　　　　　　　・dims = 大元のclusterに紐づいていたembeddings.dims
　　　　　　　　　　・vector = 所属するseedのembeddings.vectorの平均＆L2正規化
　　　　　　　　　　・is_l2_normalized = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　・layout_runsにINSERTする
　　　　　　　　　　・layout_id = 生成UUID
　　　　　　　　　　・algorithm = umap
　　　　　　　　　　・dims = 2
　　　　　　　　　　・scope_type = cluster
　　　　　　　　　　・scope_cluster_id = 生成したcluster_id
　　　　　　　　　　・params_json = {"n_components":2, "n_neighbors":15, "min_dist":0.1, "random_state":42}
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　・グループ内のcluster・seedについて、layout_pointsにINSERTする
　　　　　　　　　　・layout_id = 生成したlayout_runs.layout_id
　　　　　　　　　　・target_type = cluster / seed
　　　　　　　　　　・target_id = 該当のcluster_id /seed_id
　　　　　　　　　　・x = 0
　　　　　　　　　　・y = 0
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　・グループ内のseedに紐づいているutteranceについて、layout_pointsにINSERTする
　　　　　　　　　　・layout_id = 生成したlayout_runs.layout_id
　　　　　　　　　　・target_type = utterance
　　　　　　　　　　・target_id = 該当のutterance_id
　　　　　　　　　　・x = 0
　　　　　　　　　　・y = 0
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　・分割元が属していたlayout_runsすべてに対して、それぞれ紐づくlayout_printsをINSERTする
　　　　　　　　　　・layout_id = 分割元が属していたlayout_runs_id
　　　　　　　　　　・target_type = cluster
　　　　　　　　　　・target_id = 生成したcluster_id
　　　　　　　　　　・x = 0
　　　　　　　　　　・y = 0
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　・各要素に対してedgesをINSERTする。
　　　　　　　　　　・edge_id = 生成UUID
　　　　　　　　　　・src_type = 該当要素
　　　　　　　　　　・src_id = 該当要素のid
　　　　　　　　　　・dst_type = cluster
　　　　　　　　　　・dst_id = 生成したcluster_id
　　　　　　　　　　・edge_type = part_of
　　　　　　　　　　・weight = 二つの要素の類似度
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　　　・updated_at = 現在時刻
　　　　　　　　・worker_jobsにINSERTする。
　　　　　　　　　　・job_id = 生成UUID
　　　　　　　　　　・job_type = cluster_body
　　　　　　　　　　・target_table = clusters
　　　　　　　　　　・target_id = 生成したcluster_id
　　　　　　　　　　・status = queued
　　　　　　　　　　・priority = 5
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　　　・updated_at = 現在時刻
　　　　　　　　　　・expires_at = 現在時刻

・clusterの統合
　　・edges.dst_type = cluster、edges.edge_type = part_ofで検索したとき10件未満存在するedges.dst_idを探す。
　　　　・存在しない場合：スキップ
　　　　・存在する場合：全てのseedに紐づいているembeddings.is_l2_normalized = 1ならば、以下の処理を行う。それ以外の場合はスキップ。
　　　　　　・対象のclusterはclusters.is_archived = 1、updated_at = 現在時刻にUPDATEする。
　　　　　　・対象のclusterに紐づくedgesについて(srcとdstのどちらも確認)、is_active = 0、updated_at = 現在時刻にUPDATEする。
　　　　　　・対象のclusterに紐づくlayout_runsについて、is_active = 0にUPDATEする。
　　　　　　・対象のclusterに紐づくlayout_ruinsに属していたすべてのlayout_pointsについて、is_active = 0にUPDATEする。
　　　　　　・対象のclusterが紐づいていたlayout_pointsについて、is_active = 0にUPDATEする。
　　　　　　・近傍検索し、最も近いclusterを見つける。
　　　　　　・もともとclusterに紐づいていたseedに対して、以下の処理を行う。
　　　　　　　　・edgesをINSERTする。
　　　　　　　　　　・edge_id = 生成UUID
　　　　　　　　　　・src_type = seed
　　　　　　　　　　・src_id = 該当seed_id
　　　　　　　　　　・dst_type = cluster
　　　　　　　　　　・dst_id = 統合先のcluster_id
　　　　　　　　　　・edge_type = part_of
　　　　　　　　　　・weight = 二つの要素の類似度
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　　　・updated_at = 現在時刻
　　　　　　　　・cluster・seedについて、layout_pointsにINSERTする
　　　　　　　　　　・layout_id = 統合先のcluster_idが紐づくlayout_runs.layout_id
　　　　　　　　　　・target_type = cluster / seed
　　　　　　　　　　・target_id = 該当のcluster_id /seed_id
　　　　　　　　　　・x = 0
　　　　　　　　　　・y = 0
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　・seedに紐づいているutteranceについて、layout_pointsにINSERTする
　　　　　　　　　　・layout_id = 統合先のcluster_idが紐づくlayout_runs.layout_id
　　　　　　　　　　・target_type = utterance
　　　　　　　　　　・target_id = 該当のutterance_id
　　　　　　　　　　・x = 0
　　　　　　　　　　・y = 0
　　　　　　　　　　・is_active = 1
　　　　　　　　　　・created_at = 現在時刻
　　　　　　・統合先のclusterに対して以下の処理を行う。
　　　　　　　　・所属するseedのembeddings.vectorの平均を取得し、embeddingsにUPDATEする
　　　　　　　　　　・vector = 所属するseedのembeddings.vectorの平均
　　　　　　　　・worker_jobsにINSERTする。
　　　　　　　　　　・job_id = 生成UUID
　　　　　　　　　　・job_type = cluster_body
　　　　　　　　　　・target_table = clusters
　　　　　　　　　　・target_id = 統合先cluster_id
　　　　　　　　　　・status = queued
　　　　　　　　　　・priority = 5
　　　　　　　　　　・created_at = 現在時刻
　　　　　　　　　　・updated_at = 現在時刻
　　　　　　　　　　・expires_at = 現在時刻

・clusterの作成
　　・seed＋既存clusterを含めた近傍30件を対象にする。その中でseedが20個以上存在するかつ距離分布が中央に寄っているかつ近傍5件に既存clusterが存在しない場合、またはclusterが20個以上存在するかつ距離分布が中央に寄っている場合、両者のどちらかを満たしかつ該当要素全てに対して紐づいているembeddings.is_l2_normalized = 1ならばに、clusterを生成する。
　　　　・clustersをINSERTする
　　　　　　・cluster_id = 生成UUID
　　　　　　・cluster_level = cluster
　　　　　　・is_archived = 0
　　　　　　・created_at = 現在時刻
　　　　　　・updated_at = 現在時刻
　　　　・所属するseedのembeddings.vectorの平均を取得し、embeddingsにINSERTする
　　　　　　・embedding_id = 生成UUID
　　　　　　・target_type = cluster
　　　　　　・target_id = 生成したcluster_id
　　　　　　・model_name = paraphrase-multilingual
　　　　　　・dims = ベクトルの次元数（要素数）
　　　　　　・vector = 所属するseedのembeddings.vectorの平均＆L2正規化
　　　　　　・is_l2_normalized = 1
　　　　　　・created_at = 現在時刻
　　　　・layout_runsにINSERTする
　　　　　　・layout_id = 生成UUID
　　　　　　・algorithm = umap
　　　　　　・dims = 2
　　　　　　・scope_type = cluster
　　　　　　・scope_cluster_id = 生成したcluster_id
　　　　　　・params_json = {"n_components":2, "n_neighbors":15, "min_dist":0.1, "random_state":42}
　　　　　　・is_active = 1
　　　　　　・created_at = 現在時刻
　　　　・対象のcluster・seedについて、layout_pointsにINSERTする
　　　　　　・layout_id = 生成したlayout_runs.layout_id
　　　　　　・target_type = cluster / seed
　　　　　　・target_id = 該当のcluster_id /seed_id
　　　　　　・x = 0
　　　　　　・y = 0
　　　　　　・is_active = 1
　　　　　　・created_at = 現在時刻
　　　　・対象のseedに紐づいているutteranceについて、layout_pointsにINSERTする
　　　　　　・layout_id = 生成したlayout_runs.layout_id
　　　　　　・target_type = utterance
　　　　　　・target_id = 該当のutterance_id
　　　　　　・x = 0
　　　　　　・y = 0
　　　　　　・is_active = 1
　　　　　　・created_at = 現在時刻
　　　　・近傍を取ったlayout_runsに対して、紐づくlayout_printsをINSERTする
　　　　　　・layout_id = 近傍を取ったlayout_runs_id
　　　　　　・target_type = cluster
　　　　　　・target_id = 生成したcluster_id
　　　　　　・x = 0
　　　　　　・y = 0
　　　　　　・is_active = 1
　　　　　　・created_at = 現在時刻
　　　　・各要素に対してedgesをINSERTする。
　　　　　　・edge_id = 生成UUID
　　　　　　・src_type = 該当要素
　　　　　　・src_id = 該当要素のid
　　　　　　・dst_type = cluster
　　　　　　・dst_id = 生成したcluster_id
　　　　　　・edge_type = part_of
　　　　　　・weight = 二つの要素の類似度
　　　　　　・is_active = 1
　　　　　　・created_at = 現在時刻
　　　　　　・updated_at = 現在時刻
　　　　・worker_jobsにINSERTする。
　　　　　　・job_id = 生成UUID
　　　　　　・job_type = cluster_body
　　　　　　・target_table = clusters
　　　　　　・target_id = 生成したcluster_id
　　　　　　・status = queued
　　　　　　・priority = 5
　　　　　　・created_at = 現在時刻
　　　　　　・updated_at = 現在時刻
　　　　　　・expires_at = 現在時刻

edgesの再生成
・各seedに対して以下の処理を行う。
　　・embeddings内でvectorを用いて近傍を検索し、上位20個のutterance・seed・clusterのうち、clusterが存在した場合には上位2個に対してedgesをINSERTする。既に存在する場合には何もしない。不要となったedgesが存在する場合には、is_active = 0、updated_at = 現在時刻で更新する。
　　　　・edge_id = 生成UUID
　　　　・src_type = worker_jobs.target_table
　　　　・src_id = worker_jobs.target_id
　　　　・dst_type = cluster
　　　　・dst_id = 該当cluster_id
　　　　・edge_type = part_of
　　　　・weight = 該当clusterとworker_jobsで指定した要素の類似度
　　　　・is_active = 1
　　　　・created_at = 現在時刻
　　　　・updated_at = 現在時刻
　　・embeddings内でvectorを用いて近傍を検索し、上位10個のutterance・seed・clusterに対してedgesをINSERTする。既に存在する場合には何もしない。不要となったedgesが存在する場合には、is_active = 0、updated_at = 現在時刻で更新する。
　　　　・edge_id = 生成UUID
　　　　・src_type = worker_jobs.target_table
　　　　・src_id = worker_jobs.target_id
　　　　・dst_type = 該当要素名(utterance / seed / cluster)
　　　　・dst_id = 該当要素id(utterance_id / seed_id / cluster_id)
　　　　・edge_type = near
　　　　・weight = 該当clusterとworker_jobsで指定した要素の類似度
　　　　・is_active = 1
　　　　・created_at = 現在時刻
　　　　・updated_at = 現在時刻

layoutsの再計算
・UMAPを全てのlayout_runsそれぞれに対して実施する。layout_runsに紐づいているlayout_printsの要素のembeddings.venderを用いてx・yを算出する。
